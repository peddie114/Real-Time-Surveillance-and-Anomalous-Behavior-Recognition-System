#評估模型
loss,accuracy=model.evaluate(test_seq)
loss=history.history["loss"]
epochs=range(1,len(loss)+1)
val_loss=history.history["val_loss"]
plt.plot(epochs,loss,"bo-",label="traning loss")
plt.plot(epochs,val_loss,"ro-",label="validation loss")
plt.title("training and validation")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend(loc=0)
plt.show()


#顯示訓練和驗證準確度
ACC=history.history["accuracy"]
epochs=range(1,len(ACC)+1)
val_acc = history.history["val_accuracy"]
plt.plot(epochs, ACC, "bo-", label="Training Acc")
plt.plot(epochs, val_acc, "ro--", label="Validation Acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(loc=0)
plt.show()

for X_batch, Y_batch in test_seq:
    preds = model.predict(X_batch)  # preds shape: (batch_size, 1)
    print("預測概率 (raw):", preds.flatten())
    break

unique, counts = np.unique(Y_train, return_counts=True)
print("訓練標籤分佈：", dict(zip(unique, counts)))


y_pred_all = []
y_true_all = []

# 假設 test_seq 回傳的 Y_batch 為標量 (形狀 (batch_size,))
for X_batch, Y_batch in test_seq:
    preds = model.predict(X_batch)  # preds shape: (batch_size, 1)
    # 使用閾值 0.5 來判斷類別，因為 sigmoid 輸出
    y_pred_batch = (preds.flatten() >= 0.4).astype(int)
    y_pred_all.append(y_pred_batch)
    y_true_all.append(Y_batch.flatten())

y_pred_all = np.concatenate(y_pred_all, axis=0)
y_true_all = np.concatenate(y_true_all, axis=0)

conf_mat = confusion_matrix(y_true_all, y_pred_all)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=["Normal", "Abnormal"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

print("y_pred_all:", y_pred_all)
print("y_true_all:", y_true_all)


print("Confusion Matrix:")
cm=confusion_matrix(y_true_all,y_pred_all)
print(cm)
# 使用 classification_report 輸出詳細報告
report=classification_report(y_true_all,y_pred_all,target_names=["Normal","Abnormal"])
print("Classification Report:\n",report)
#分別計算 Recall,F1,Precision
precision=precision_score(y_true_all,y_pred_all,pos_label=1)
f1=f1_score(y_true_all, y_pred_all, pos_label=1)
recall=recall_score(y_true_all, y_pred_all, pos_label=1)
print(f"Precision (Abnormal): {precision:.3f}")
print(f"Recall (Abnormal): {recall:.3f}")
print(f"F1-score (Abnormal): {f1:.3f}")

#以假設的驗證結果畫出異常分數的直方圖
#anomaly_Score 異常分數
#ground_truth 真實標籤
anomaly_scores=np.array([0.4,0.88,0.123,0.9,0.22,0.7,0.1,0.56])
ground_truth=np.array([0,1,1,0,1,0,1,1])
plt.hist(anomaly_scores, bins=20, color="skyblue", edgecolor="black")
plt.xlabel("異常數")
plt.ylabel("clip count")
plt.title("異常數的分佈")
plt.show()



from sklearn.calibration import calibration_curve
pred_probs = model.predict(test_seq)
pred_probs = pred_probs.flatten()
prob_true, prob_pred = calibration_curve(y_true_all, pred_probs, n_bins=10)

plt.figure(figsize=(8, 5))
plt.plot(prob_pred, prob_true, marker='o', label='Calibration curve')
plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')
plt.xlabel('預測機率')
plt.ylabel('真實概率')
plt.title('預測校準曲線')
plt.legend()
plt.show()
from sklearn.metrics import brier_score_loss

brier = brier_score_loss(y_true_all, pred_probs)
print("Brier 分數:", brier)




